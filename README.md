# ğŸ“Š Income Prediction Using Decision Tree Regression

This project aims to predict individual income using a complete Machine Learning workflow.  
The dataset contains demographic, education, employment, and household-related attributes, and the model uses a Decision Tree Regressor with full hyperparameter tuning to estimate income values.

---

## ğŸš€ Project Overview
- Perform data cleaning and preprocessing.
- Apply Ordinal and One-Hot Encoding to categorical features.
- Use log transformation to reduce skewness in the target variable.
- Split data into training and testing sets.
- Use **GridSearchCV** to optimize tree hyperparameters.
- Evaluate model performance (RÂ², RMSE).
- Visualize predicted vs actual income values.

---

## ğŸ› ï¸ Technologies Used
- Python  
- Pandas  
- NumPy  
- Scikit-Learn  
- Plotly  
- Jupyter Notebook
- Google Colab

---

## ğŸ”§ Model Details
- **Algorithm:** Decision Tree Regression  
- **Tuning:**  
  - `max_depth`  
  - `min_samples_leaf`  
  - `min_samples_split`  
- **Scoring:** Negative Mean Squared Error (MSE)  
- **Target:** Income (log-transformed during training)

---

## ğŸ“ˆ Results
Due to the synthetic nature of the dataset, the model shows:
- **Training RÂ² :**  low  
- **Testing  RÂ² :**   low  
This indicates **underfitting**, meaning the dataset lacks strong relationships between features and income.

Despite this, the project demonstrates a clean, end-to-end ML pipeline suitable for learning and experimentation.

---

## ğŸ“ Files Included
- **data.csv** â†’ Dataset used for training and tetsing the model
- **Income Prediction Project No LogTransformation.ipynb** â†’  Main notebook containing full ML workflow without log transformation applied ( higher in the accuracy )
- **Income Prediction with Log Trasnfromation.ipynb** â†’  Another version of the notebook containing full ML workflow with log transformation applied ( lower in the accuracy )
- **README.md** â†’ Project documentation

---

## ğŸ“ˆ Results
Due to the synthetic nature of the dataset and the selected model ( Decision Tree Regression ) , the model shows **underfitting**, with low RÂ² scores on the both notebooks .  
- **Income Prediction Project No LogTransformation.ipyn** â†’ Rsquared = 1.68%
- **Income Prediction Project with Log Trasnfromation.ipyn** â†’ Rsquared = -8.54%
This demonstrates a realistic challenge when datasets lack strong featureâ€“target relationships.

---

## ğŸ¯ Future Improvements
- Try ensemble models: RandomForest, GradientBoosting, XGBoost  
- Use a more realistic dataset  
- Apply advanced feature engineering to extract meaningful patterns  

---

## ğŸ‘¤ Author
Developed by **Samir Mohamed** as part of a regression machine learning practice project.
